{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver. 1\n",
    "slow AF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import logging\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse, urlunparse\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from typing import Set, Dict, Any, Optional\n",
    "from requests_cache import CachedSession\n",
    "from collections import deque\n",
    "from colorsys import hsv_to_rgb\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from queue import Queue, Empty\n",
    "\n",
    "# Настройка логгирования\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"website_graph.log\", encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def html_title(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    container = soup.new_tag('div')\n",
    "    container.append(soup)\n",
    "    return container\n",
    "\n",
    "\n",
    "class WebsiteGraph:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_url: str,\n",
    "        max_depth: int = 2,\n",
    "        domain_filter: Optional[str] = None,\n",
    "        path_regex: Optional[str] = None,\n",
    "        node_size: str = \"degree\",\n",
    "        layout: Optional[Dict[str, Any]] = None,\n",
    "        max_links: int = 10,\n",
    "        expire_after: int = 3000\n",
    "    ):\n",
    "        \"\"\"Класс для построения и визуализации графа веб-сайта.\n",
    "    \n",
    "    Args:\n",
    "        start_url (str): Начальный URL для парсинга.\n",
    "        max_depth (int, optional): Максимальная глубина обхода. Defaults to 2.\n",
    "        domain_filter (str, optional): Домен для фильтрации ссылок. Defaults to None.\n",
    "        path_regex (str, optional): Регулярное выражение для путей. Defaults to None.\n",
    "        node_size (str, optional): Метод расчета размера узлов. Defaults to \"degree\".\n",
    "        layout (Dict[str, Any], optional): Параметры визуализации. Defaults to None.\n",
    "        max_links (int, optional): Максимум ссылок на страницу. Defaults to 10.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Инициализация парсера с параметрами: \"\n",
    "                    f\"start_url={start_url}, max_depth={max_depth}, \"\n",
    "                    f\"domain_filter={domain_filter}, path_regex={path_regex}, \"\n",
    "                    f\"node_size={node_size}, max_links={max_links}\")\n",
    "        \n",
    "        self.graph = nx.DiGraph()\n",
    "        self.start_url = self._normalize_url(start_url)\n",
    "        self.max_depth = max_depth\n",
    "        self.domain = urlparse(self.start_url).netloc\n",
    "        self.domain_filter = domain_filter or self.domain\n",
    "        self.path_regex = re.compile(path_regex) if path_regex else None\n",
    "        self.node_size = node_size\n",
    "        self.layout = layout or {\"physics\": True, \"hierarchical\": False}\n",
    "        self.max_links = max_links\n",
    "        self.expire_after = expire_after\n",
    "        self.visited = set()\n",
    "                # Инициализация кэшированной сессии\n",
    "        self.session = CachedSession(\n",
    "            cache_name=f'cache/{urlparse(self.start_url).netloc}',  # Отдельный кэш для каждого домена [[2]]\n",
    "            expire_after=self.expire_after,\n",
    "            allowable_methods=('GET',)  # Кэшируем только GET-запросы [[7]]\n",
    "        )\n",
    "        # Отключаем ненужные проверки для ускорения\n",
    "        self.session.verify = True  # Используйте с осторожностью! Для HTTPS лучше включить проверку\n",
    "         \n",
    "    def _normalize_url(self, url: str) -> str:\n",
    "        \"\"\"Нормализует URL, удаляя якори и дублирующие слеши.\n",
    "        \n",
    "        Args:\n",
    "            url (str): Исходный URL.\n",
    "            \n",
    "        Returns:\n",
    "            str: Нормализованный URL.\n",
    "        \"\"\"\n",
    "        parsed = urlparse(url)\n",
    "        normalized = urlunparse((\n",
    "            parsed.scheme,\n",
    "            parsed.netloc,\n",
    "            parsed.path.rstrip('/'),  # Удаляем trailing slash\n",
    "            '',  # params\n",
    "            parsed.query,  # Сохраняем query-параметры\n",
    "            ''   # fragment\n",
    "        ))\n",
    "        return normalized\n",
    "\n",
    "    def _get_article_title(self, url: str) -> str:\n",
    "        \"\"\"Упрощенная версия с использованием walrus operator\"\"\"\n",
    "        if (match := re.search(r'/wiki/([^/]+)', url)) and (title := match.group(1)):\n",
    "            return title.replace('_', ' ')\n",
    "        return url.split('//')[-1].split('/')[0]  # Альтернатива для не-wiki URL\n",
    "\n",
    "    def _is_valid_url(self, url: str) -> bool:\n",
    "        \"\"\"Проверяет валидность URL согласно фильтрам.\n",
    "        \n",
    "        Args:\n",
    "            url (str): Проверяемый URL.\n",
    "            \n",
    "        Returns:\n",
    "            bool: True, если URL соответствует условиям.\n",
    "        \"\"\"\n",
    "        parsed = urlparse(url)\n",
    "        is_main_page = parsed.path.lower().endswith('main_page')\n",
    "        valid = (\n",
    "            self.domain_filter in parsed.netloc and\n",
    "            not is_main_page and\n",
    "            (not self.path_regex or self.path_regex.search(parsed.path))\n",
    "        )\n",
    "        if not valid:\n",
    "            logger.debug(f\"URL отклонен: {url} (домен: {parsed.netloc}, путь: {parsed.path})\")\n",
    "        return valid\n",
    "    \n",
    "    def _extract_links(self, url: str):\n",
    "        \"\"\"Извлекает ссылки со страницы с кэшированием.\n",
    "        Args:\n",
    "            url (str): URL страницы для парсинга.\n",
    "        Returns:\n",
    "            Tuple[Set[str], Optional[int]]: Множество валидных ссылок и HTTP-статус.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Парсинг ссылок с: {url}\")\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=5)\n",
    "            response.raise_for_status()  # Вызывает HTTPError для 4xx/5xx\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            links = set()\n",
    "            for link in soup.find_all(\"a\", href=True):\n",
    "                full_url = urljoin(url, link[\"href\"])\n",
    "                normalized_url = self._normalize_url(full_url)\n",
    "                if self._is_valid_url(normalized_url):\n",
    "                    links.add(normalized_url)\n",
    "                    if len(links) >= self.max_links:\n",
    "                        logger.debug(f\"Достигнут лимит ссылок ({self.max_links}) для {url}\")\n",
    "                        break\n",
    "            logger.debug(f\"Найдено {len(links)} валидных ссылок на странице\")\n",
    "            return links, response.status_code  # Возвращаем статус успешного ответа\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            # Обработка HTTP-ошибок (4xx/5xx)\n",
    "            status_code = e.response.status_code if e.response else None\n",
    "            logger.error(f\"HTTP ошибка {status_code} для {url}: {str(e)}\", exc_info=True)\n",
    "            return set(), status_code\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Обработка сетевых ошибок (timeout, connection error)\n",
    "            logger.error(f\"Сетевая ошибка для {url}: {str(e)}\", exc_info=True)\n",
    "            return set(), None\n",
    "\n",
    "        except Exception as e:\n",
    "            # Обработка остальных исключений\n",
    "            logger.error(f\"Непредвиденная ошибка для {url}: {str(e)}\", exc_info=True)\n",
    "            return set(), None\n",
    "\n",
    "    def _crawl(self, force_reload: bool = False) -> None:\n",
    "        \"\"\"Рекурсивно обходит сайт, строя граф ссылок.\"\"\"\n",
    "        self.start_crawl_time = time.time()\n",
    "        if not force_reload and self.graph.nodes:\n",
    "            logger.info(\"Используем существующий граф\")\n",
    "            return\n",
    "        logger.info(\"Начинаем обход сайта\")\n",
    "        queue = deque([(self.start_url, 0)])\n",
    "        current_depth = 0  # Начальная глубина\n",
    "        with tqdm(total=self.max_depth, desc=\"Глубина обхода\") as pbar:\n",
    "            while queue:\n",
    "                url, depth = queue.popleft()\n",
    "                logger.debug(f\"Обрабатываем URL: {url} (глубина: {depth}/{self.max_depth})\")\n",
    "                \n",
    "                # Обновляем прогресс-бар при переходе на новый уровень глубины\n",
    "                if depth > current_depth:\n",
    "                    pbar.update(depth - current_depth)\n",
    "                    current_depth = depth\n",
    "                    logger.info(f\"Переход на глубину: {current_depth}\")\n",
    "                    \n",
    "                if depth > self.max_depth or url in self.visited:\n",
    "                    logger.debug(f\"Пропуск URL: {url} (посещено: {url in self.visited}, глубина: {depth})\")\n",
    "                    continue\n",
    "                    \n",
    "                self.visited.add(url)\n",
    "                logger.info(f\"Добавление узла: {url} (глубина: {depth})\")\n",
    "                \n",
    "                links, status_code = self._extract_links(url)\n",
    "                if status_code:  # Если статус получен (успешный запрос)\n",
    "                    self.graph.add_node(\n",
    "                        url,\n",
    "                        title=url,\n",
    "                        label=self._get_article_title(url),\n",
    "                        size=self._calculate_node_size(url),\n",
    "                        status_code=status_code,  # Сохраняем статус\n",
    "                        depth=depth \n",
    "                    )\n",
    "                else:  # Если произошла ошибка\n",
    "                    self.graph.add_node(\n",
    "                        url,\n",
    "                        title=url,\n",
    "                        label=self._get_article_title(url),\n",
    "                        size=self._calculate_node_size(url),\n",
    "                        status_code=0,  # Или другое значение по умолчанию\n",
    "                        depth=depth \n",
    "                    )\n",
    "                \n",
    "                '''links, status = self._extract_links(url)\n",
    "                self.graph.add_node(\n",
    "                    url,\n",
    "                    title=url,\n",
    "                    label=self._get_article_title(url),\n",
    "                    size=self._calculate_node_size(url)\n",
    "                )\n",
    "                '''\n",
    "                for link in links:\n",
    "                    if url != link:\n",
    "                        logger.debug(f\"Добавление связи: {url} -> {link}\")\n",
    "                        #print(f\"Добавление связи: {url} -> {link}\")\n",
    "                        self.graph.add_edge(url, link)\n",
    "                        queue.extend((link, depth+1) for link in links)\n",
    "        self.end_crawl_time = time.time()\n",
    "\n",
    "    def _calculate_node_size(self, node: str) -> int:\n",
    "        \"\"\"Рассчитывает размер узла на основе входящих связей.\n",
    "        \n",
    "        Args:\n",
    "            node (str): URL узла.\n",
    "            \n",
    "        Returns:\n",
    "            int: Размер узла в пикселях.\n",
    "        \"\"\"\n",
    "        in_degree = dict(self.graph.in_degree()).get(node, 0)\n",
    "        size = 10 + 3 * in_degree if self.node_size == \"degree\" else 10\n",
    "        logger.debug(f\"Размер узла {node} рассчитан как {size} (входящих связей: {in_degree})\")\n",
    "        return size\n",
    "      \n",
    "    def _get_node_color(self, node: str) -> str:\n",
    "        \"\"\"Вычисляет цвет узла от светло-зеленого до рыжего\n",
    "        Args:\n",
    "            node (str): URL узла\n",
    "        Returns:\n",
    "            str: HEX-код цвета\n",
    "        \"\"\"\n",
    "        if self.max_degree == self.min_degree:\n",
    "            return \"#D4EDD4\"  # Светло-зеленый для графа без связей [[2]]\n",
    "        \n",
    "        t = (self.graph.in_degree(node) - self.min_degree) / (self.max_degree - self.min_degree)\n",
    "        \n",
    "        # Интерполяция от зеленого (h=0.33) к рыжему (h=0.08) [[6]]\n",
    "        h = 0.33 - 0.25 * t  # 0.33 (зеленый) → 0.08 (рыжий)\n",
    "        s = 0.8 + 0.2 * t    # Увеличение насыщенности для темных оттенков\n",
    "        v = 0.9 + 0.1 * t    # Увеличение яркости для светлых участков\n",
    "        \n",
    "        r, g, b = hsv_to_rgb(h, s, v)\n",
    "        return '#{:02x}{:02x}{:02x}'.format(\n",
    "            int(r*255), int(g*255), int(b*255)\n",
    "        )\n",
    "\n",
    "    def visualize(self, rebuild: bool = False, force_reload: bool = False) -> None:\n",
    "        \"\"\"Создает HTML-визуализацию графа с использованием pyvis.\"\"\"\n",
    "        if rebuild or force_reload or not self.graph.nodes:\n",
    "            self._crawl(force_reload=force_reload)\n",
    "        logger.info(\"Запуск визуализации графа\")\n",
    "        \n",
    "        \n",
    "        if not self.graph.nodes:\n",
    "            logger.warning(\"Граф пуст - визуализация невозможна\")\n",
    "            return\n",
    "        \n",
    "        # Расчет границ градиента\n",
    "        self.degree_map = dict(self.graph.in_degree())\n",
    "        self.min_degree = min(self.degree_map.values()) if self.degree_map else 1\n",
    "        self.max_degree = max(self.degree_map.values()) if self.degree_map else 1\n",
    "        logger.debug(f\"Градиент границы: min={self.min_degree}, max={self.max_degree}\")\n",
    "\n",
    "        net = Network(\n",
    "            notebook=False,\n",
    "            directed=True,\n",
    "            height=\"800px\",\n",
    "            width=\"100%\",\n",
    "            cdn_resources=\"remote\"\n",
    "        )\n",
    "        \n",
    "        # Настройки подсветки\n",
    "        options = {\n",
    "            \"edges\": {\n",
    "                \"color\": {\n",
    "                    \"color\": \"#2B7CE9\",  # Стандартный цвет\n",
    "                    \"highlight\": \"#FF0000\",  # Цвет подсветки\n",
    "                    \"hover\": \"#FF0000\"       # Цвет при наведении\n",
    "                },\n",
    "                \"selectionWidth\": 3,  # Толщина выделенных рёбер\n",
    "                \"smooth\": False\n",
    "            },\n",
    "            \"interaction\": {\n",
    "                \"hoverConnectedEdges\": True,\n",
    "                \"selectConnectedEdges\": True,  # Автоматический выбор связанных рёбер\n",
    "                \"multiselect\": True,\n",
    "                \"navigationButtons\": True,\n",
    "                \"keyboard\":True,\n",
    "                \"hover\": True,\n",
    "                \"click\": True,\n",
    "            },\n",
    "            \"physics\": {\n",
    "                \"enabled\": True,\n",
    "                \"forceAtlas2Based\": {\n",
    "                    \"gravitationalConstant\": -200,  # Увеличьте отталкивание (от -50 до -500)\n",
    "                    \"springLength\": 500,           # Длина связей между узлами (от 100 до 500)\n",
    "                    \"springConstant\": 0.001,        # Жесткость связей (от 0.001 до 0.1)\n",
    "                    \"damping\": 0.3,                # Затухание движения (0-1)\n",
    "                    \"avoidOverlap\": 1              # Избегать пересечений (0-1)\n",
    "                },\n",
    "                \"stabilization\": {\n",
    "                    \"iterations\": 500,             # Итераций для стабилизации\n",
    "                    \"updateInterval\": 50\n",
    "                }\n",
    "            },\n",
    "            \"nodes\": {\n",
    "                \"allow_html\": True,  # Включаем поддержку HTML\n",
    "                \"shape\": \"box\",  # Обязательно для кликабельности [[8]]\n",
    "                \"font\": {\"size\": 10},\n",
    "                \"color\": {\n",
    "                    \"border\": \"#2B7CE9\",\n",
    "                    \"background\": \"#97C2FC\",\n",
    "                    \"highlight\": {\n",
    "                        \"border\": \"#FF0000\",  # Цвет границы узла при выделении\n",
    "                        \"background\": \"#FFFF00\"\n",
    "                    }\n",
    "                },\n",
    "                \"chosen\": True,\n",
    "                \"style\": \"cursor: pointer;\",\n",
    "                \"shapeProperties\": {\n",
    "                    \"allowHtml\": True  # Правильный параметр вместо allow_html [[9]]\n",
    "                    }\n",
    "            },\n",
    "        \n",
    "            \"configure\": {\n",
    "                \"enabled\": False,\n",
    "                \"filter\": \"nodes,edges\",\n",
    "                \"showButton\": False\n",
    "            },\n",
    "            \"version\": \"9.1.2\" \n",
    "            }\n",
    "\n",
    "        net.set_options(json.dumps(options))\n",
    "        for node in self.graph.nodes:\n",
    "            \n",
    "            # Формирование HTML-подсказки\n",
    "            status_code = self.graph.nodes[node].get('status_code', 0)\n",
    "            in_degree = self.graph.in_degree(node)\n",
    "            status_color = \"#e6ffe6\"  # Зеленый фон по умолчанию\n",
    "            \n",
    "            tooltip = (\n",
    "            f\"<div style='padding: 8px; background: {status_color}'>\"\n",
    "            f\"<b>URL:</b> {node}<br>\"\n",
    "            f\"<b>Status:</b> {status_code}<br>\"\n",
    "            f\"<b>In-Degree:</b> {in_degree}<br>\"\n",
    "            f\"</div>\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "            title = self._get_article_title(node)\n",
    "            if status_code and 400 <= int(status_code) < 600:\n",
    "                color = \"#ffcccc\"  # Красный фон для ошибок\n",
    "            else:\n",
    "                color = self._get_node_color(node)\n",
    "            color = self._get_node_color(node)  # <- Новое вычисление цвета\n",
    "            logger.debug(f\"Добавление узла в визуализацию: {node} (заголовок: {title})\")\n",
    "            logger.debug(f\"Цвет узла {node}: {color} (степень: {self.graph.in_degree(node)})\")\n",
    "            \n",
    "            # В цикле добавления узлов\n",
    "            full_url = node if node.startswith((\"http://\", \"https://\")) else f\"http://{node}\"\n",
    "            escaped_url = full_url.replace(\"'\", \"\\\\'\")  # Экранируем одинарные кавычки [[4]]\n",
    "\n",
    "            \n",
    "            net.add_node(\n",
    "                node,\n",
    "                label=title,\n",
    "                title=tooltip,\n",
    "                size=self._calculate_node_size(node),\n",
    "                color=color,\n",
    "                url=full_url,\n",
    "                allow_html=True,\n",
    "                # Добавляем обработчик клика через JavaScript\n",
    "                onclick=f\"window.open('{escaped_url}', '_blank');\",\n",
    "                shapeProperties={\n",
    "                \"allowHtml\": True  # Корректное название опции [[1]]\n",
    "            },\n",
    "            )\n",
    "\n",
    "        for edge in self.graph.edges:\n",
    "            logger.debug(f\"Добавление связи в визуализацию: {edge[0]} -> {edge[1]}\")\n",
    "            net.add_edge(edge[0], edge[1])\n",
    "\n",
    "        ipynb_dir =  '\\\\'.join(get_this_ipynb().split('\\\\')[:-1])\n",
    "        directory = ensure_directory_exists(ipynb_dir + '\\\\graphs')\n",
    "        try:\n",
    "            graph_num = [int(i.split('.')[0].replace('graph','')) for i in list_files(directory)][-1]+1\n",
    "        except:\n",
    "            graph_num = 0\n",
    "        logger.info(\"Сохранение графа в HTML-файл\")\n",
    "        file = f\"{directory}\\\\graph{graph_num}.html\"\n",
    "        \n",
    "        text = f'{file} | max_depth: {self.max_depth} | max_links: {self.max_links} | crawl time: {self.end_crawl_time - self.start_crawl_time}'\n",
    "        \n",
    "        net.write_html(file, open_browser=True)\n",
    "        append_to_file(ipynb_dir+f'\\\\{self.__name__().split('.')[-1]}.txt',text)\n",
    "        \n",
    "        \n",
    "        logger.info(f\"Graph saved as {file} and opened in browser\")\n",
    "        \n",
    "        \n",
    "        print(text)\n",
    "        \n",
    "        \n",
    "        # Нужно закрыть сессию)\n",
    "        self.session.close()\n",
    "    \n",
    "    def __name__(self):\n",
    "        return 'WebsiteGraph'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Пример использования\\nlogging.disable(logging.CRITICAL)\\nfor i in [1,2,3]:\\n    logger.info(\"Запуск программы\")\\n\\n    graph = WebsiteGraph(\\n        start_url=\"https://en.wikipedia.org/wiki/Data_science\",\\n        max_depth=i,\\n        max_links=10,\\n        path_regex=r\"^/wiki/[A-Za-z_]+$\",\\n        layout={\"physics\": True}\\n    )\\n\\n    graph._crawl()\\n    graph.visualize()'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Пример использования\n",
    "logging.disable(logging.CRITICAL)\n",
    "for i in [1,2,3]:\n",
    "    logger.info(\"Запуск программы\")\n",
    "\n",
    "    graph = WebsiteGraph(\n",
    "        start_url=\"https://en.wikipedia.org/wiki/Data_science\",\n",
    "        max_depth=i,\n",
    "        max_links=10,\n",
    "        path_regex=r\"^/wiki/[A-Za-z_]+$\",\n",
    "        layout={\"physics\": True}\n",
    "    )\n",
    "\n",
    "    graph._crawl()\n",
    "    graph.visualize()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results:\n",
    "\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph0.html | max_depth: 1 | max_links: 10 | crawl time: 1.6000185012817383\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph2.html | max_depth: 2 | max_links: 10 | crawl time: 12.905709743499756\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph4.html | max_depth: 3 | max_links: 10 | crawl time: 84.55941534042358\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph0.html | max_depth: 1 | max_links: 10 | crawl time: 3.058067798614502\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph1.html | max_depth: 2 | max_links: 10 | crawl time: 20.718218088150024\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph2.html | max_depth: 3 | max_links: 10 | crawl time: 123.30372500419617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver 2\n",
    "fast af\n",
    "multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import logging\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from urllib.parse import urljoin, urlparse, urlunparse\n",
    "from bs4 import BeautifulSoup\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from requests_cache import CachedSession\n",
    "from colorsys import hsv_to_rgb\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"website_graph.log\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class WebsiteGraphMP: # MP for MultiProcessing\n",
    "    def __init__(self,\n",
    "                 start_url: str,\n",
    "                 max_depth: int = 2,\n",
    "                 max_links: int = 5,\n",
    "                 path_regex: str = None,\n",
    "                 workers: int = 10,\n",
    "                 expire_after: int = 3000,\n",
    "                 node_size: str = \"degree\",\n",
    "                 layout: dict = None,\n",
    "                 ):\n",
    "        self.start_url = self._normalize_url(start_url)\n",
    "        self.max_depth = max_depth\n",
    "        self.max_links = max_links\n",
    "        self.domain = urlparse(self.start_url).netloc\n",
    "        self.path_regex = re.compile(path_regex) if path_regex else None\n",
    "        self.workers = workers\n",
    "        self.expire_after = expire_after\n",
    "        self.node_size = node_size\n",
    "        self.layout = layout or {\"physics\": True, \"hierarchical\": False}\n",
    "        self.graph = nx.DiGraph()\n",
    "        \n",
    "        try:\n",
    "            self.results = self._prev_results()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def detect_communities(self):\n",
    "        from networkx.algorithms import community\n",
    "        return list(community.greedy_modularity_communities(self.graph))\n",
    "     \n",
    "    def _normalize_url(self, url: str) -> str:\n",
    "        parsed = urlparse(url)\n",
    "        normalized = urlunparse((\n",
    "            parsed.scheme,\n",
    "            parsed.netloc,\n",
    "            parsed.path.rstrip('/'),\n",
    "            \"\",\n",
    "            parsed.query,\n",
    "            \"\"\n",
    "        ))\n",
    "        return normalized\n",
    "\n",
    "    def _is_valid_url(self, url: str) -> bool:\n",
    "        parsed = urlparse(url)\n",
    "        # Avoid main page and require same domain\n",
    "        is_main_page = parsed.path.lower().endswith(\"main_page\")\n",
    "        valid = (self.domain in parsed.netloc and not is_main_page and \n",
    "                 (not self.path_regex or self.path_regex.search(parsed.path)))\n",
    "        return valid\n",
    "\n",
    "    def _get_article_title(self, url: str) -> str:\n",
    "        match = re.search(r'/wiki/([^/]+)', url)\n",
    "        if match:\n",
    "            return match.group(1).replace('_', ' ')\n",
    "        return url.split('//')[-1].split('/')[0]\n",
    "\n",
    "    def fetch_page(self, url: str, depth: int, session: CachedSession):\n",
    "        \"\"\"Fetch a page, extract valid links, and return node data with found links.\"\"\"\n",
    "        logger.info(f\"Fetching (depth {depth}): {url}\")\n",
    "        try:\n",
    "            response = session.get(url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            links = set()\n",
    "            for link in soup.find_all(\"a\", href=True):\n",
    "                full_url = urljoin(url, link[\"href\"])\n",
    "                normalized_url = self._normalize_url(full_url)\n",
    "                if self._is_valid_url(normalized_url):\n",
    "                    links.add(normalized_url)\n",
    "                    if len(links) >= self.max_links:\n",
    "                        break\n",
    "            node_data = {\n",
    "                \"title\": self._get_article_title(url),\n",
    "                \"label\": self._get_article_title(url),\n",
    "                \"status_code\": response.status_code,\n",
    "                \"depth\": depth\n",
    "            }\n",
    "            return node_data, links\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            status_code = e.response.status_code if e.response else None\n",
    "            logger.error(f\"HTTP error {status_code} for {url}: {str(e)}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Network error for {url}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error for {url}: {str(e)}\")\n",
    "        # In case of error, return minimal data with no links.\n",
    "        node_data = {\n",
    "            \"title\": self._get_article_title(url),\n",
    "            \"label\": self._get_article_title(url),\n",
    "            \"status_code\": None,\n",
    "            \"depth\": depth\n",
    "        }\n",
    "        return node_data, set()\n",
    "\n",
    "    def process_url(self, url: str, depth: int, session: CachedSession, visited: set):\n",
    "        \"\"\"Process a URL and update the graph. Always return a set of links for further processing.\"\"\"\n",
    "        if url in visited:\n",
    "            return set()\n",
    "        visited.add(url)\n",
    "        node_data, links = self.fetch_page(url, depth, session)\n",
    "        # Remove self-loops and avoid duplicate edges\n",
    "        valid_links = {link for link in links if link != url}\n",
    "        self.graph.add_node(url, **node_data)\n",
    "        for link in valid_links:\n",
    "            # Avoid duplicate edge creation\n",
    "            if not self.graph.has_edge(url, link):\n",
    "                self.graph.add_edge(url, link)\n",
    "        # Only return links for further processing if within max_depth.\n",
    "        return valid_links if depth < self.max_depth else set()\n",
    "\n",
    "    def crawl(self):\n",
    "        \"\"\"Crawl the website using a ThreadPoolExecutor.\"\"\"\n",
    "        try:\n",
    "            print(f'Predicted time for crawling: {self._predict_time(self.max_depth,self.max_links,self.workers)}')\n",
    "        except:\n",
    "            pass # Because it only works when _prev_results works\n",
    "        \n",
    "        \n",
    "        self.start_crawl_time = time.time()\n",
    "        logger.info(\"Starting crawl\")\n",
    "        session = CachedSession(\n",
    "            cache_name=f\"cache/{self.domain}\",\n",
    "            expire_after=self.expire_after,\n",
    "            allowable_methods=(\"GET\",)\n",
    "        )\n",
    "        session.verify = True\n",
    "        \n",
    "        visited = set()\n",
    "        frontier = [(self.start_url, 0)]\n",
    "        with ThreadPoolExecutor(max_workers=self.workers) as executor:\n",
    "            while frontier:\n",
    "                futures = {}\n",
    "                for url, depth in frontier:\n",
    "                    if url not in visited:\n",
    "                        future = executor.submit(self.process_url, url, depth, session, visited)\n",
    "                        futures[future] = depth\n",
    "                frontier = []\n",
    "                for future in futures:\n",
    "                    links = future.result() or set()\n",
    "                    current_depth = futures[future]\n",
    "                    if current_depth < self.max_depth:\n",
    "                        for link in links:\n",
    "                            if link not in visited:\n",
    "                                frontier.append((link, current_depth + 1))\n",
    "        self.end_crawl_time = time.time()                    \n",
    "        # Нужно закрыть сессию)\n",
    "        session.close()\n",
    "        logger.info(\"Crawl complete\")\n",
    "        \n",
    "    \n",
    "    def _calculate_node_size(self, node: str) -> int:\n",
    "        in_degree = self.graph.in_degree(node)\n",
    "        size = 10 + 3 * in_degree if self.node_size == \"degree\" else 10\n",
    "        return size\n",
    "\n",
    "    def _get_node_color(self, node: str) -> str:\n",
    "        \n",
    "        if self.max_degree == self.min_degree:\n",
    "            return \"#D4EDD4\"\n",
    "        t = (self.graph.in_degree(node) - self.min_degree) / (self.max_degree - self.min_degree)\n",
    "        h = 0.33 - 0.25 * t\n",
    "        s = 0.8 + 0.2 * t\n",
    "        v = 0.9 + 0.1 * t\n",
    "        r, g, b = hsv_to_rgb(h, s, v)\n",
    "        return '#{:02x}{:02x}{:02x}'.format(int(r * 255), int(g * 255), int(b * 255))\n",
    "    \n",
    "    def _prev_results(self):\n",
    "        with open('WebsiteGraphMP.txt') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        names = ['name','max_depth', 'max_links','crawl_time','workers']\n",
    "\n",
    "\n",
    "        results = []\n",
    "        for i in list(map(lambda x: x.split(\"|\"), lines)):\n",
    "            if len(i) == len(names):\n",
    "                results.append([_.split(':')[-1] for _ in i])\n",
    "        results = pd.DataFrame(results, columns=names)\n",
    "        results['name'] = results['name'].transform(lambda x: x.split('\\\\')[-1])\n",
    "        results['max_depth'] = pd.to_numeric(results['max_depth'])\n",
    "        results['max_links'] = pd.to_numeric(results['max_links'])\n",
    "        results['crawl_time'] = pd.to_numeric(results['crawl_time'])\n",
    "        results['workers'] = pd.to_numeric(results['workers'].transform(lambda x: x[:-1]))\n",
    "        results.set_index('name', inplace=True)\n",
    "        results.sort_values('crawl_time', inplace=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _predict_time(self,max_depth,max_links,workers):\n",
    "        gran_mean_times = self.results.groupby(['max_depth','max_links','workers'])[['crawl_time']].agg(['mean'])\n",
    "        noworkers_mean_times = self.results.groupby(['max_depth','max_links'])[['crawl_time']].agg(['mean'])\n",
    "        \n",
    "        if (max_depth,max_links,workers) in gran_mean_times.index:\n",
    "            return gran_mean_times.loc[max_depth,max_links,workers].iloc[0]\n",
    "        \n",
    "        elif (max_depth,max_links) in noworkers_mean_times.index:\n",
    "            return noworkers_mean_times.loc[max_depth,max_links].iloc[0]\n",
    "        \n",
    "        else:\n",
    "            X = self.results[['max_depth','max_links','workers']].values\n",
    "            y = self.results['crawl_time'].values\n",
    "\n",
    "            X = PolynomialFeatures(degree=2).fit_transform(X)\n",
    "            model1 = OLS(y,X)\n",
    "            model1 = model1.fit()\n",
    "\n",
    "\n",
    "            mean_times = self.results[self.results.max_links==10].groupby('max_depth')[['crawl_time']].agg(['mean'])\n",
    "            x = PolynomialFeatures(degree=2).fit_transform(mean_times.index.values.reshape(-1,1))\n",
    "\n",
    "            model2 = OLS(mean_times.values,x)\n",
    "            model2 = model2.fit()\n",
    "\n",
    "            return (model1.predict(PolynomialFeatures(degree=2).fit_transform([[max_depth,max_links,workers]]))[0] + model2.predict(PolynomialFeatures(degree=2).fit_transform([[max_depth]]))[0])/2\n",
    "        \n",
    "    def visualize(self, rebuild: bool = False, force_reload: bool = False, force_file_name : str = ''):\n",
    "        if rebuild or force_reload or not self.graph.nodes:\n",
    "            self.crawl()\n",
    "        degrees = [self.graph.in_degree(n) for n in self.graph.nodes()]\n",
    "        self.min_degree = min(degrees) if degrees else 0\n",
    "        self.max_degree = max(degrees) if degrees else 1\n",
    "        logger.info(\"Starting visualization\")\n",
    "\n",
    "        net = Network(\n",
    "            notebook=False, \n",
    "            directed=True, \n",
    "            height=\"800px\", \n",
    "            width=\"100%\", \n",
    "            cdn_resources=\"remote\",\n",
    "            bgcolor = '#000000',\n",
    "            font_color = '#ffffff'\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Example custom physics to help prevent node overlap\n",
    "        net.repulsion(\n",
    "            node_distance=500,\n",
    "            central_gravity=0.2,\n",
    "            spring_length=200,\n",
    "            spring_strength=0.05,\n",
    "            damping=0.09\n",
    "        )\n",
    "        net.font_color\n",
    "        #net.set_options(json.dumps(options))\n",
    "        for node in self.graph.nodes:\n",
    "            data = self.graph.nodes[node]\n",
    "            status_code = data.get(\"status_code\", 0)\n",
    "            in_degree = self.graph.in_degree(node)\n",
    "            tooltip = (\n",
    "                f\"<div style='padding: 8px; background: #e6ffe6'>\"\n",
    "                f\"<b>URL:</b> {node}<br>\"\n",
    "                f\"<b>Status:</b> {status_code}<br>\"\n",
    "                f\"<b>In-Degree:</b> {in_degree}<br>\"\n",
    "                f\"</div>\"\n",
    "            )\n",
    "            title = data.get(\"label\", node)\n",
    "            color = \"#ffcccc\" if status_code and 400 <= int(status_code) < 600 else self._get_node_color(node)\n",
    "            full_url = node if node.startswith((\"http://\", \"https://\")) else f\"http://{node}\"\n",
    "            escaped_url = full_url.replace(\"'\", \"\\\\'\")\n",
    "            net.add_node(\n",
    "                node,\n",
    "                label=self._get_article_title(title),\n",
    "                title=tooltip,\n",
    "                size=self._calculate_node_size(node),\n",
    "                font={\"size\": self._calculate_node_size(node)},\n",
    "                color=color,\n",
    "                url=full_url,\n",
    "                onclick=f\"window.open('{escaped_url}', '_blank');\",\n",
    "                shapeProperties={\"allowHtml\": True}\n",
    "            )\n",
    "\n",
    "        # Avoid duplicate edges by checking existing net.edges (list of dicts)\n",
    "        for edge in self.graph.edges:\n",
    "            src, dst = edge\n",
    "            if src != dst:\n",
    "                # Check if there's an existing edge from src to dst\n",
    "                if not any(e[\"from\"] == src and e[\"to\"] == dst for e in net.edges):\n",
    "                    net.add_edge(\n",
    "                        src,\n",
    "                        dst,\n",
    "                        color={\n",
    "                            \"color\": \"#2B7CE9\",\n",
    "                            \"highlight\": \"#FF0000\",\n",
    "                            \"hover\": \"#FF0000\"\n",
    "                            },\n",
    "                        selectionWidth=3,\n",
    "                        smooth=False\n",
    "                        )\n",
    "                    \n",
    "        ipynb_dir =  '\\\\'.join(get_this_ipynb().split('\\\\')[:-1])\n",
    "        directory = ensure_directory_exists(ipynb_dir + '\\\\graphs')\n",
    "        \n",
    "        if not len(force_file_name):\n",
    "            \n",
    "            try:\n",
    "                graph_num = max([int(i.split('.')[0].replace('graph','')) for i in list_files(directory) if 'graph' in i.split('.')[0]])+1\n",
    "            except:\n",
    "                graph_num = 0\n",
    "            \n",
    "            file = f\"{directory}\\\\graph{graph_num}.html\"\n",
    "        else:\n",
    "            file = f\"{directory}\\\\{force_file_name}.html\"\n",
    "        logger.info(\"Сохранение графа в HTML-файл\")\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            text = f'{file} | max_depth: {self.max_depth} | max_links: {self.max_links} | crawl time: {self.end_crawl_time - self.start_crawl_time} | workers: {self.workers}'\n",
    "        except:\n",
    "            text = f'{file} | max_depth: {self.max_depth} | max_links: {self.max_links} | workers: {self.workers}'\n",
    "        net.write_html(file, open_browser=True)\n",
    "        append_to_file(ipynb_dir+f'\\\\{self.__name__().split('.')[-1]}.txt',text)\n",
    "        \n",
    "        \n",
    "        logger.info(f\"Graph saved as {file} and opened in browser\")\n",
    "        \n",
    "        \n",
    "        print(text)\n",
    "    \n",
    "        # Magic Methods\n",
    "    def __str__(self):\n",
    "        return (f\"WebsiteGraphMP(start_url='{self.start_url}', nodes={self.graph.number_of_nodes()}, \"\n",
    "                f\"edges={self.graph.number_of_edges()})\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"WebsiteGraphMP(start_url='{self.start_url}', max_depth={self.max_depth}, \"\n",
    "                f\"max_links={self.max_links}, workers={self.workers})\")\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, WebsiteGraphMP):\n",
    "            return NotImplemented\n",
    "        # Compare start_url and basic graph structure (nodes and edges)\n",
    "        return (self.start_url == other.start_url and\n",
    "                nx.is_isomorphic(self.graph, other.graph))\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "            if not isinstance(other, WebsiteGraphMP):\n",
    "                return NotImplemented\n",
    "\n",
    "            # Use NetworkX's compose to get the union of the two graphs.\n",
    "            # (Nodes present in both graphs will be merged; edge sets are united.)\n",
    "            new_graph = nx.compose(self.graph, other.graph)\n",
    "\n",
    "            # Invent union logic for parameters:\n",
    "            # For example, use the start_url from self, and pick the more permissive (max) values.\n",
    "            new_max_depth = max(self.max_depth, other.max_depth)\n",
    "            new_max_links = max(self.max_links, other.max_links)\n",
    "            new_workers = max(self.workers, other.workers)\n",
    "            new_expire_after = max(self.expire_after, other.expire_after)\n",
    "\n",
    "            # For regex pattern, choose self's pattern if available, otherwise other.\n",
    "            new_path_regex = None\n",
    "            if self.path_regex and other.path_regex:\n",
    "                new_path_regex = self.path_regex.pattern if len(self.path_regex.pattern) >= len(other.path_regex.pattern) else other.path_regex.pattern\n",
    "            elif self.path_regex:\n",
    "                new_path_regex = self.path_regex.pattern\n",
    "            elif other.path_regex:\n",
    "                new_path_regex = other.path_regex.pattern\n",
    "\n",
    "            # Create a new WebsiteGraph instance with unioned parameters.\n",
    "            new_instance = WebsiteGraphMP(\n",
    "                start_url=self.start_url,  # you can decide which one to use\n",
    "                max_depth=new_max_depth,\n",
    "                max_links=new_max_links,\n",
    "                path_regex=new_path_regex,\n",
    "                workers=new_workers,\n",
    "                expire_after=new_expire_after,\n",
    "                layout=self.layout  # or merge layouts if needed\n",
    "            )\n",
    "            # Set the union graph\n",
    "            new_instance.graph = new_graph\n",
    "\n",
    "            return new_instance\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        # In-place union: merge other's graph into self\n",
    "        if not isinstance(other, WebsiteGraphMP):\n",
    "            return NotImplemented\n",
    "        self.graph = nx.compose(self.graph, other.graph)\n",
    "        self.max_depth = max(self.max_depth, other.max_depth)\n",
    "        self.max_links = max(self.max_links, other.max_links)\n",
    "        self.workers = max(self.workers, other.workers)\n",
    "        self.expire_after = max(self.expire_after, other.expire_after)\n",
    "        # For path_regex and layout, you can choose to keep self's parameters.\n",
    "        return self\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        if not isinstance(other, WebsiteGraphMP):\n",
    "            return NotImplemented\n",
    "        # Subtract nodes found in the other graph from self.graph\n",
    "        new_instance = WebsiteGraphMP(\n",
    "            start_url=self.start_url,\n",
    "            max_depth=self.max_depth,\n",
    "            max_links=self.max_links,\n",
    "            path_regex=self.path_regex.pattern if self.path_regex else None,\n",
    "            workers=self.workers,\n",
    "            expire_after=self.expire_after,\n",
    "            layout=self.layout\n",
    "        )\n",
    "        new_instance.graph = self.graph.copy()\n",
    "        for node in other.graph.nodes():\n",
    "            if node in new_instance.graph:\n",
    "                new_instance.graph.remove_node(node)\n",
    "        return new_instance\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Iterate over nodes as (node, attributes) tuples.\n",
    "        return iter(self.graph.nodes(data=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.graph.number_of_nodes()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Allow indexing by node ID to get node attributes.\n",
    "        return self.graph.nodes[key]\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.graph\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.graph.number_of_nodes() > 0\n",
    "\n",
    "    def __call__(self):\n",
    "        # Calling the instance triggers a re-crawl.\n",
    "        self.crawl()\n",
    "        return self        \n",
    "    \n",
    "    def __name__(self):\n",
    "        return 'WebsiteGraphMP'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WebsiteGraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 02:08:59,414 - INFO - Starting program\n",
      "2025-03-29 02:08:59,423 - INFO - Starting crawl\n",
      "2025-03-29 02:08:59,428 - INFO - Fetching (depth 0): https://en.wikipedia.org/wiki/Data_science\n",
      "2025-03-29 02:08:59,491 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Statistics\n",
      "2025-03-29 02:08:59,491 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Scientific_method\n",
      "2025-03-29 02:08:59,492 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Interdisciplinary\n",
      "2025-03-29 02:08:59,493 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Astronomical_survey\n",
      "2025-03-29 02:08:59,495 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Scientific_computing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted time for crawling: 2.051242619752884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 02:08:59,499 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Computer_science\n",
      "2025-03-29 02:08:59,528 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Information_science\n",
      "2025-03-29 02:08:59,544 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Comet_NEOWISE\n",
      "2025-03-29 02:08:59,729 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Space_telescope\n",
      "2025-03-29 02:09:00,721 - INFO - Crawl complete\n",
      "2025-03-29 02:09:00,723 - INFO - Starting visualization\n",
      "2025-03-29 02:09:11,127 - INFO - Сохранение графа в HTML-файл\n",
      "2025-03-29 02:09:11,269 - INFO - Graph saved as c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph13.html and opened in browser\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph13.html | max_depth: 1 | max_links: 10 | crawl time: 1.2987685203552246 | workers: 10\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting program\")\n",
    "graph1 = WebsiteGraphMP(\n",
    "    start_url=\"https://en.wikipedia.org/wiki/Data_science\",\n",
    "    max_depth=1,\n",
    "    max_links=10,\n",
    "    path_regex=r\"^/wiki/[A-Za-z_]+$\",\n",
    "    workers=10,\n",
    "    layout={\"physics\": True}\n",
    ")()\n",
    "\n",
    "\n",
    "graph1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logger.info(\"Starting program\")\\ngraph1 = WebsiteGraphMP(\\n    start_url=\"https://en.wikipedia.org/wiki/Data_science\",\\n    max_depth=3,\\n    max_links=10,\\n    path_regex=r\"^/wiki/[A-Za-z_]+$\",\\n    workers=10,\\n    layout={\"physics\": True}\\n)()\\n# Call instance to crawl\\n\\nprint(graph1)  # Uses __str__\\nprint(repr(graph1))  # Uses __repr__\\n# Iterate over nodes\\nfor node, data in graph1:\\n    print(node, data)\\n# Check length\\nprint(\"Total nodes:\", len(graph1))\\n# Check membership\\nprint(\"Contains \\'https://en.wikipedia.org/wiki/Data_science\\':\", \"https://en.wikipedia.org/wiki/Data_science\" in graph1)\\n\\ngraph1.visualize()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''logger.info(\"Starting program\")\n",
    "graph1 = WebsiteGraphMP(\n",
    "    start_url=\"https://en.wikipedia.org/wiki/Data_science\",\n",
    "    max_depth=3,\n",
    "    max_links=10,\n",
    "    path_regex=r\"^/wiki/[A-Za-z_]+$\",\n",
    "    workers=10,\n",
    "    layout={\"physics\": True}\n",
    ")()\n",
    "# Call instance to crawl\n",
    "\n",
    "print(graph1)  # Uses __str__\n",
    "print(repr(graph1))  # Uses __repr__\n",
    "# Iterate over nodes\n",
    "for node, data in graph1:\n",
    "    print(node, data)\n",
    "# Check length\n",
    "print(\"Total nodes:\", len(graph1))\n",
    "# Check membership\n",
    "print(\"Contains 'https://en.wikipedia.org/wiki/Data_science':\", \"https://en.wikipedia.org/wiki/Data_science\" in graph1)\n",
    "\n",
    "graph1.visualize()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph1 = WebsiteGraphMP(\\n    start_url=\"https://en.wikipedia.org/wiki/Data_science\",\\n    max_depth=4,\\n    max_links=10,\\n    path_regex=r\"^/wiki/[A-Za-z_]+$\",\\n    workers=10,\\n    layout={\"physics\": True}\\n)\\ngraph1()\\n\\ngraph1.visualize(force_file_name = \\'4d.10l.10w\\')'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''graph1 = WebsiteGraphMP(\n",
    "    start_url=\"https://en.wikipedia.org/wiki/Data_science\",\n",
    "    max_depth=4,\n",
    "    max_links=10,\n",
    "    path_regex=r\"^/wiki/[A-Za-z_]+$\",\n",
    "    workers=10,\n",
    "    layout={\"physics\": True}\n",
    ")\n",
    "graph1()\n",
    "\n",
    "graph1.visualize(force_file_name = '4d.10l.10w')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results:\n",
    "\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph3.html | max_depth: 1 | max_links: 10 | crawl time: 1.1849431991577148 | workers: 10\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph4.html | max_depth: 1 | max_links: 10 | crawl time: 1.4319779872894287 | workers: 20\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph5.html | max_depth: 2 | max_links: 10 | crawl time: 12.662982702255249 | workers: 10\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph6.html | max_depth: 2 | max_links: 10 | crawl time: 13.79235053062439 | workers: 20\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph7.html | max_depth: 3 | max_links: 10 | crawl time: 66.65576791763306 | workers: 10\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph8.html | max_depth: 3 | max_links: 10 | crawl time: 62.48543572425842 | workers: 20\n",
    "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\graph9.html | max_depth: 4 | max_links: 10 | crawl time: 264.98015880584717 | workers: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_depth=4,\n",
    "max_links=10`\n",
    "<br>\n",
    "С этими параметрами - визуализация проблематична, но строится относительно быстро, можно пользоваться как графом этой структурой можно спокойно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph1 = WebsiteGraphMP(start_url=\"https://en.wikipedia.org/wiki/Data_science\", max_depth=1, max_links=10, path_regex=r\"^/wiki/[A-Za-z_]+$\")\\ngraph1()\\n\\ngraph2 = WebsiteGraphMP(start_url=\"https://en.wikipedia.org/wiki/Artificial_intelligence\", max_depth=1, max_links=10, path_regex=r\"^/wiki/[A-Za-z_]+$\")\\ngraph2()\\n\\nunion_graph = graph1 + graph2\\nunion_graph.visualize()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''graph1 = WebsiteGraphMP(start_url=\"https://en.wikipedia.org/wiki/Data_science\", max_depth=1, max_links=10, path_regex=r\"^/wiki/[A-Za-z_]+$\")\n",
    "graph1()\n",
    "\n",
    "graph2 = WebsiteGraphMP(start_url=\"https://en.wikipedia.org/wiki/Artificial_intelligence\", max_depth=1, max_links=10, path_regex=r\"^/wiki/[A-Za-z_]+$\")\n",
    "graph2()\n",
    "\n",
    "union_graph = graph1 + graph2\n",
    "union_graph.visualize()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting time for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crawl_time  mean    286.954203\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = graph1._prev_results()\n",
    "gran_mean_times = results.groupby(['max_depth','max_links','workers'])[['crawl_time']].agg(['mean'])\n",
    "gran_mean_times.loc[4,10].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2373.619695016165"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = results[['max_depth','max_links','workers']].values\n",
    "y = results['crawl_time'].values\n",
    "\n",
    "X = PolynomialFeatures(degree=2).fit_transform(X)\n",
    "model = OLS(y,X)\n",
    "model = model.fit()\n",
    "model.summary()\n",
    "\n",
    "model.predict(PolynomialFeatures(degree=2).fit_transform([[10,10,10]]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 02:09:11,806 - INFO - Starting program\n",
      "2025-03-29 02:09:11,813 - INFO - Starting crawl\n",
      "2025-03-29 02:09:11,817 - INFO - Fetching (depth 0): https://en.wikipedia.org/wiki/Pornhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted time for crawling: 5.0946913957595825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 02:09:12,196 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Pornography\n",
      "2025-03-29 02:09:12,196 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Media_conglomerate\n",
      "2025-03-29 02:09:12,197 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Talk:Pornhub\n",
      "2025-03-29 02:09:12,198 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornhub\n",
      "2025-03-29 02:09:12,200 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornhub\n",
      "2025-03-29 02:09:12,202 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Privately_held_company\n",
      "2025-03-29 02:09:12,203 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/List_of_most-visited_websites\n",
      "2025-03-29 02:09:12,206 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Pornhub&oldid=1281899413\n",
      "2025-03-29 02:09:12,209 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Pornhub&id=1281899413&wpFormIdentifier=titleform\n",
      "2025-03-29 02:09:12,213 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Sex_industry\n",
      "2025-03-29 02:09:12,242 - ERROR - Unable to deserialize response: a bytes-like object is required, not 'NoneType'\n",
      "2025-03-29 02:09:12,439 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Pornhub&action=history\n",
      "2025-03-29 02:09:12,476 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Pornhub&printable=yes\n",
      "2025-03-29 02:09:12,530 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Online_advertising\n",
      "2025-03-29 02:09:12,531 - ERROR - Unexpected error for https://en.wikipedia.org/w/index.php?title=Pornhub&action=history: bad parameter or other API misuse\n",
      "2025-03-29 02:09:12,532 - ERROR - Unable to deserialize response: a bytes-like object is required, not 'NoneType'\n",
      "2025-03-29 02:09:12,534 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornhub\n",
      "2025-03-29 02:09:12,657 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Quebec\n",
      "2025-03-29 02:09:13,035 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Pornhub&action=info\n",
      "2025-03-29 02:09:13,302 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornhub\n",
      "2025-03-29 02:09:13,328 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Holding_company\n",
      "2025-03-29 02:09:13,352 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Ethical_Capital_Partners\n",
      "2025-03-29 02:09:13,402 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Video_sharing\n",
      "2025-03-29 02:09:13,806 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Aylo\n",
      "2025-03-29 02:09:13,885 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Pornhub&action=edit\n",
      "2025-03-29 02:09:13,941 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Montreal\n",
      "2025-03-29 02:09:14,029 - ERROR - Unexpected error for https://en.wikipedia.org/w/index.php?title=Pornhub&action=edit: bad parameter or other API misuse\n",
      "2025-03-29 02:09:14,080 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Organizational_founder\n",
      "2025-03-29 02:09:14,102 - INFO - Fetching (depth 1): https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Pornhub&action=show-download-screen\n",
      "2025-03-29 02:09:14,106 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Amateur_pornography\n",
      "2025-03-29 02:09:14,166 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/File:Pornhub-logo.svg\n",
      "2025-03-29 02:09:14,194 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Internet_pornography\n",
      "2025-03-29 02:09:14,472 - INFO - Fetching (depth 1): https://en.wikipedia.org/wiki/Service_(economics)\n",
      "2025-03-29 02:09:16,215 - INFO - Crawl complete\n",
      "2025-03-29 02:09:16,219 - INFO - Starting visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebsiteGraphMP(start_url='https://en.wikipedia.org/wiki/Pornhub', nodes=580, edges=664)\n",
      "WebsiteGraphMP(start_url='https://en.wikipedia.org/wiki/Pornhub', max_depth=1, max_links=30, workers=10)\n",
      "https://en.wikipedia.org/wiki/Pornhub {'title': 'Pornhub', 'label': 'Pornhub', 'status_code': 200, 'depth': 0}\n",
      "https://en.wikipedia.org/wiki/Pornography {'title': 'Pornography', 'label': 'Pornography', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Media_conglomerate {'title': 'Media conglomerate', 'label': 'Media conglomerate', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Talk:Pornhub {'title': 'Talk:Pornhub', 'label': 'Talk:Pornhub', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornhub {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornhub {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Privately_held_company {'title': 'Privately held company', 'label': 'Privately held company', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/List_of_most-visited_websites {'title': 'List of most-visited websites', 'label': 'List of most-visited websites', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&oldid=1281899413 {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Pornhub&id=1281899413&wpFormIdentifier=titleform {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Sex_industry {'title': 'Sex industry', 'label': 'Sex industry', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&action=history {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': None, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&printable=yes {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Online_advertising {'title': 'Online advertising', 'label': 'Online advertising', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornhub {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Quebec {'title': 'Quebec', 'label': 'Quebec', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&action=info {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornhub {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Holding_company {'title': 'Holding company', 'label': 'Holding company', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Ethical_Capital_Partners {'title': 'Ethical Capital Partners', 'label': 'Ethical Capital Partners', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Video_sharing {'title': 'Video sharing', 'label': 'Video sharing', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Aylo {'title': 'Aylo', 'label': 'Aylo', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&action=edit {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': None, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Montreal {'title': 'Montreal', 'label': 'Montreal', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Organizational_founder {'title': 'Organizational founder', 'label': 'Organizational founder', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Pornhub&action=show-download-screen {'title': 'en.wikipedia.org', 'label': 'en.wikipedia.org', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Amateur_pornography {'title': 'Amateur pornography', 'label': 'Amateur pornography', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/File:Pornhub-logo.svg {'title': 'File:Pornhub-logo.svg', 'label': 'File:Pornhub-logo.svg', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Internet_pornography {'title': 'Internet pornography', 'label': 'Internet pornography', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Service_(economics) {'title': 'Service (economics)', 'label': 'Service (economics)', 'status_code': 200, 'depth': 1}\n",
      "https://en.wikipedia.org/wiki/Concentration_of_media_ownership {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&oldid=1280712926 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Media_conglomerate&id=1280712926&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Media_conglomerate&action=show-download-screen {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Mass_media {}\n",
      "https://en.wikipedia.org/wiki/Motion_picture {}\n",
      "https://en.wikipedia.org/wiki/Publishing {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:Log&type=review&page=Media_conglomerate {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Media+conglomerate {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMedia_conglomerate {}\n",
      "https://en.wikipedia.org/wiki/Conglomerate_(company) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Radio {}\n",
      "https://en.wikipedia.org/wiki/Talk:Media_conglomerate {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&action=info {}\n",
      "https://en.wikipedia.org/wiki/Television {}\n",
      "https://en.wikipedia.org/wiki/Music {}\n",
      "https://en.wikipedia.org/wiki/Amusement_park {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/wiki/The_Nation {}\n",
      "https://en.wikipedia.org/wiki/Company {}\n",
      "https://en.wikipedia.org/wiki/Subsidiary {}\n",
      "https://en.wikipedia.org/wiki/Internet {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMedia_conglomerate {}\n",
      "https://en.wikipedia.org/wiki/Video_game {}\n",
      "https://en.wikipedia.org/w/index.php?title=Media_conglomerate&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Media+conglomerate {}\n",
      "https://en.wikipedia.org/wiki/Share_(finance) {}\n",
      "https://en.wikipedia.org/wiki/Stock {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/wiki/Independent_company_(military) {}\n",
      "https://en.wikipedia.org/wiki/Talk:Privately_held_company {}\n",
      "https://en.wikipedia.org/wiki/Over-the-counter_(finance) {}\n",
      "https://en.wikipedia.org/wiki/Economy {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPrivately_held_company {}\n",
      "https://en.wikipedia.org/wiki/United_States {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&action=history {}\n",
      "https://en.wikipedia.org/wiki/State_ownership {}\n",
      "https://en.wikipedia.org/wiki/Eastern_Bloc {}\n",
      "https://en.wikipedia.org/wiki/State-owned_enterprises {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Privately+held+company {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPrivately_held_company {}\n",
      "https://en.wikipedia.org/wiki/Collective_ownership {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Privately_held_company&id=1277206740&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/List_of_largest_private_non-governmental_companies_by_revenue {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Privately+held+company {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Privately_held_company&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/File:Question_book-new.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Small_businesses {}\n",
      "https://en.wikipedia.org/wiki/Public_company {}\n",
      "https://en.wikipedia.org/wiki/Private_equity {}\n",
      "https://en.wikipedia.org/w/index.php?title=Privately_held_company&oldid=1277206740 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FList_of_most-visited_websites {}\n",
      "https://en.wikipedia.org/wiki/Google {}\n",
      "https://en.wikipedia.org/w/index.php?title=List_of_most-visited_websites&action=history {}\n",
      "https://en.wikipedia.org/wiki/YouTube {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=List_of_most-visited_websites&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Twitter {}\n",
      "https://en.wikipedia.org/wiki/WhatsApp {}\n",
      "https://en.wikipedia.org/w/index.php?title=List_of_most-visited_websites&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=List_of_most-visited_websites&action=info {}\n",
      "https://en.wikipedia.org/wiki/ChatGPT {}\n",
      "https://en.wikipedia.org/w/index.php?title=List_of_most-visited_websites&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Talk:List_of_most-visited_websites {}\n",
      "https://en.wikipedia.org/wiki/Instagram {}\n",
      "https://en.wikipedia.org/wiki/Reddit {}\n",
      "https://en.wikipedia.org/wiki/OpenAI {}\n",
      "https://en.wikipedia.org/wiki/Meta_Platforms {}\n",
      "https://en.wikipedia.org/wiki/List_of_social_platforms_with_at_least_100_million_active_users {}\n",
      "https://en.wikipedia.org/wiki/Semrush {}\n",
      "https://en.wikipedia.org/wiki/Facebook {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=List+of+most-visited+websites {}\n",
      "https://en.wikipedia.org/wiki/Google_Search {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=List+of+most-visited+websites {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=List_of_most-visited_websites&id=1282360292&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=List_of_most-visited_websites&oldid=1282360292 {}\n",
      "https://en.wikipedia.org/wiki/X_Corp. {}\n",
      "https://en.wikipedia.org/wiki/Wikimedia_Foundation {}\n",
      "https://en.wikipedia.org/wiki/Similarweb {}\n",
      "https://en.wikipedia.org/wiki/Nonprofit_organization {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FList_of_most-visited_websites {}\n",
      "https://en.wikipedia.org/w/index.php?title=Sex_industry&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSex_industry {}\n",
      "https://en.wikipedia.org/wiki/Sex_toys {}\n",
      "https://en.wikipedia.org/wiki/Talk:Sex_industry {}\n",
      "https://en.wikipedia.org/wiki/Strip_clubs {}\n",
      "https://en.wikipedia.org/wiki/Film_set {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Sex+industry {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSex_industry {}\n",
      "https://en.wikipedia.org/w/index.php?title=Sex_industry&action=info {}\n",
      "https://en.wikipedia.org/wiki/Adult_entertainment_(disambiguation) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Sex+industry {}\n",
      "https://en.wikipedia.org/wiki/Porno_film {}\n",
      "https://en.wikipedia.org/w/index.php?title=Sex_industry&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Women%27s_magazine {}\n",
      "https://en.wikipedia.org/wiki/Prostitution {}\n",
      "https://en.wikipedia.org/w/index.php?title=Sex_industry&oldid=1278510889 {}\n",
      "https://en.wikipedia.org/wiki/BDSM {}\n",
      "https://en.wikipedia.org/wiki/File:Porn_Set_5.jpg {}\n",
      "https://en.wikipedia.org/wiki/Host_and_hostess_clubs {}\n",
      "https://en.wikipedia.org/w/index.php?title=Sex_industry&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Sex_industry&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Pornographic_film {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Sex_industry&id=1278510889&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Sexual_fetishism {}\n",
      "https://en.wikipedia.org/wiki/Men%27s_magazine {}\n",
      "https://en.wikipedia.org/wiki/Sex_trade_(disambiguation) {}\n",
      "https://en.wikipedia.org/wiki/Video_on_demand {}\n",
      "https://en.wikipedia.org/wiki/Prepayment_for_service {}\n",
      "https://en.wikipedia.org/wiki/MHRA_Style_Guide {}\n",
      "https://en.wikipedia.org/wiki/The_MLA_Style_Manual {}\n",
      "https://en.wikipedia.org/wiki/LaTeX {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Special%3ACiteThisPage&returntoquery=id%3D1281899413%26page%3DPornhub%26wpFormIdentifier%3Dtitleform {}\n",
      "https://en.wikipedia.org/wiki/Tertiary_source {}\n",
      "https://en.wikipedia.org/wiki/Council_of_Science_Editors {}\n",
      "https://en.wikipedia.org/wiki/APA_style {}\n",
      "https://en.wikipedia.org/wiki/BibTeX {}\n",
      "https://en.wikipedia.org/wiki/Bluebook {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Special%3ACiteThisPage&returntoquery=id%3D1281899413%26page%3DPornhub%26wpFormIdentifier%3Dtitleform {}\n",
      "https://en.wikipedia.org/wiki/American_Medical_Association {}\n",
      "https://en.wikipedia.org/wiki/The_Chicago_Manual_of_Style {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3ACiteThisPage%26id%3D1281899413%26page%3DPornhub%26wpFormIdentifier%3Dtitleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3ACiteThisPage%26id%3D1281899413%26page%3DPornhub%26wpFormIdentifier%3Dtitleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26oldid%3D1281899413 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornhub&returntoquery=oldid%3D1281899413 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&diff=prev&oldid=1281899413 {}\n",
      "https://en.wikipedia.org/wiki/User_talk:America1257 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornhub&returntoquery=oldid%3D1281899413 {}\n",
      "https://en.wikipedia.org/wiki/User_talk:Parksfan1955 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&direction=prev&oldid=1281899413 {}\n",
      "https://en.wikipedia.org/wiki/User:Parksfan1955 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26oldid%3D1281899413 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Special%3AUrlShortener&returntoquery=url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Special%3AUrlShortener&returntoquery=url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3AUrlShortener%26url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/wiki/Cave_painting {}\n",
      "https://en.wikipedia.org/wiki/Eug%C3%A8ne_Pirou {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornography&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornography {}\n",
      "https://en.wikipedia.org/wiki/Erotica {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Pornography&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Sexual_arousal {}\n",
      "https://en.wikipedia.org/wiki/Sexual_suggestiveness {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornography {}\n",
      "https://en.wikipedia.org/wiki/Fanny_Hill {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornography&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornography&oldid=1282824003 {}\n",
      "https://en.wikipedia.org/wiki/Virtual_reality_sex {}\n",
      "https://en.wikipedia.org/wiki/Talk:Pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Pornography&id=1282824003&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Kama_Sutra {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornography {}\n",
      "https://en.wikipedia.org/wiki/File:XXX_P_icon.svg {}\n",
      "https://en.wikipedia.org/wiki/Le_Coucher_de_la_Mari%C3%A9e {}\n",
      "https://en.wikipedia.org/wiki/Artifact_(archaeology) {}\n",
      "https://en.wikipedia.org/wiki/The_Kiss_(1896_film) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornography&action=history {}\n",
      "https://en.wikipedia.org/wiki/History_of_erotic_depictions {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornography&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Pornography_(disambiguation) {}\n",
      "https://en.wikipedia.org/wiki/Western_world {}\n",
      "https://en.wikipedia.org/wiki/Thomas_Edison {}\n",
      "https://en.wikipedia.org/wiki/Porn_(disambiguation) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&action=edit&section=new {}\n",
      "https://en.wikipedia.org/wiki/Category:Unassessed_company_articles {}\n",
      "https://en.wikipedia.org/wiki/File:Symbol_c_class.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&oldid=1281087040 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTalk%3APornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub_Awards&redirect=no {}\n",
      "https://en.wikipedia.org/wiki/Talk:Pornhub/Archive_1 {}\n",
      "https://en.wikipedia.org/wiki/Category:Mid-importance_company_articles {}\n",
      "https://en.wikipedia.org/wiki/Category:Company_articles_needing_attention {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub_Awards&action=history {}\n",
      "https://en.wikipedia.org/wiki/User:DannyS712 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Talk%3APornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Talk%3APornhub&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/File:Nuvola_apps_korganizer.svg {}\n",
      "https://en.wikipedia.org/wiki/File:Crystal128-eraser.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Talk%3APornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTalk%3APornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub&action=edit {}\n",
      "https://en.wikipedia.org/wiki/User_talk:Minecrafter0271 {}\n",
      "https://en.wikipedia.org/wiki/User:Minecrafter0271 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Talk:Pornhub_Awards&redirect=no {}\n",
      "https://en.wikipedia.org/wiki/File:Clipboard.svg {}\n",
      "https://en.wikipedia.org/wiki/File:Factory_1b.svg {}\n",
      "https://en.wikipedia.org/wiki/User_talk:DannyS712 {}\n",
      "https://en.wikipedia.org/wiki/Display_advertising {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_advertising&action=history {}\n",
      "https://en.wikipedia.org/wiki/Affiliate_marketing {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOnline_advertising {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Online_advertising&id=1259492306&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Pay-per-click {}\n",
      "https://en.wikipedia.org/wiki/Local_search_engine_optimisation {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_advertising&oldid=1259492306 {}\n",
      "https://en.wikipedia.org/wiki/Talk:Online_advertising {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOnline_advertising {}\n",
      "https://en.wikipedia.org/wiki/Contextual_advertising {}\n",
      "https://en.wikipedia.org/wiki/Email_marketing {}\n",
      "https://en.wikipedia.org/wiki/Web_analytics {}\n",
      "https://en.wikipedia.org/wiki/Search_engine_optimization {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_advertising&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Content_marketing {}\n",
      "https://en.wikipedia.org/wiki/Cost_per_impression {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Online+advertising {}\n",
      "https://en.wikipedia.org/wiki/Social_media_marketing {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_advertising&action=info {}\n",
      "https://en.wikipedia.org/wiki/Ad_blocking {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Online_advertising&action=show-download-screen {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Online+advertising {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_advertising&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Referral_marketing {}\n",
      "https://en.wikipedia.org/wiki/Search_engine_marketing {}\n",
      "https://en.wikipedia.org/wiki/Native_advertising {}\n",
      "https://en.wikipedia.org/wiki/Search_analytics {}\n",
      "https://en.wikipedia.org/wiki/Behavioral_targeting {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3AQrCode%26url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Special%3AQrCode&returntoquery=url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3AQrCode%26url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Special%3AQrCode&returntoquery=url%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FPornhub {}\n",
      "https://en.wikipedia.org/wiki/Province_of_Quebec_(1763%E2%80%931791) {}\n",
      "https://en.wikipedia.org/wiki/Coat_of_arms_of_Quebec {}\n",
      "https://en.wikipedia.org/w/index.php?title=Quebec&action=info {}\n",
      "https://en.wikipedia.org/wiki/Saskatchewan {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Quebec {}\n",
      "https://en.wikipedia.org/wiki/Geographic_coordinate_system {}\n",
      "https://en.wikipedia.org/w/index.php?title=Quebec&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Provinces_and_territories_of_Canada {}\n",
      "https://en.wikipedia.org/w/index.php?title=Quebec&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FQuebec {}\n",
      "https://en.wikipedia.org/wiki/Quebec_City {}\n",
      "https://en.wikipedia.org/wiki/Quebec_(disambiguation) {}\n",
      "https://en.wikipedia.org/wiki/French_language {}\n",
      "https://en.wikipedia.org/wiki/Ontario {}\n",
      "https://en.wikipedia.org/w/index.php?title=Quebec&oldid=1282711611 {}\n",
      "https://en.wikipedia.org/wiki/Manitoba {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Quebec {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FQuebec {}\n",
      "https://en.wikipedia.org/wiki/Flag_of_Quebec {}\n",
      "https://en.wikipedia.org/wiki/Quebec_French {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Quebec&id=1282711611&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Talk:Quebec {}\n",
      "https://en.wikipedia.org/wiki/File:Coat_of_arms_of_Quebec.svg {}\n",
      "https://en.wikipedia.org/wiki/Je_me_souviens {}\n",
      "https://en.wikipedia.org/wiki/British_Columbia {}\n",
      "https://en.wikipedia.org/wiki/File:Flag_of_Quebec.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Quebec&action=history {}\n",
      "https://en.wikipedia.org/wiki/Alberta {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Quebec&action=show-download-screen {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornhub&returntoquery=printable%3Dyes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26printable%3Dyes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornhub&returntoquery=printable%3Dyes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26printable%3Dyes {}\n",
      "https://en.wikipedia.org/wiki/Template:Canada-company-stub {}\n",
      "https://en.wikipedia.org/wiki/Talk:Ethical_Capital_Partners {}\n",
      "https://en.wikipedia.org/wiki/Template_talk:Canada-company-stub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Ethical_Capital_Partners&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Category:2022_establishments_in_Quebec {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEthical_Capital_Partners {}\n",
      "https://en.wikipedia.org/wiki/Private_equity_firm {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEthical_Capital_Partners {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Rape_pornography {}\n",
      "https://en.wikipedia.org/wiki/Category:Private_equity_firms_of_Canada {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Ethical+Capital+Partners {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&oldid=1282434620 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Ethical+Capital+Partners {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Ethical_Capital_Partners&id=1282434620&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Rocco_Meliambro {}\n",
      "https://en.wikipedia.org/wiki/ISSN_(identifier) {}\n",
      "https://en.wikipedia.org/wiki/File:Canada-company-stub-logo.png {}\n",
      "https://en.wikipedia.org/w/index.php?title=Ethical_Capital_Partners&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Over-the-top_content {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&oldid=1279157074 {}\n",
      "https://en.wikipedia.org/wiki/Quality_of_service {}\n",
      "https://en.wikipedia.org/wiki/Talk:Online_video_platform {}\n",
      "https://en.wikipedia.org/wiki/User-generated_content {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/wiki/Software_as_a_service {}\n",
      "https://en.wikipedia.org/wiki/Do_it_yourself {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Online_video_platform&id=1279157074&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/API {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Online_video_analytics {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOnline_video_platform {}\n",
      "https://en.wikipedia.org/wiki/Video_player {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOnline_video_platform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Online_video_platform&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Private_server {}\n",
      "https://en.wikipedia.org/wiki/Online_video_platform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Video_sharing&redirect=no {}\n",
      "https://en.wikipedia.org/w/index.php?title=Online_video_platform&action=info {}\n",
      "https://en.wikipedia.org/wiki/Quality_of_experience {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Online+video+platform {}\n",
      "https://en.wikipedia.org/wiki/Heat_map {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Online+video+platform {}\n",
      "https://en.wikipedia.org/wiki/Category:Use_Canadian_English_from_August_2019 {}\n",
      "https://en.wikipedia.org/w/index.php?title=User:Phyprt&action=edit&redlink=1 {}\n",
      "https://en.wikipedia.org/wiki/User_talk:Phyprt {}\n",
      "https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_August_2024 {}\n",
      "https://en.wikipedia.org/wiki/Category:CS1:_unfit_URL {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26action%3Dinfo {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DPornhub%26action%3Dinfo {}\n",
      "https://en.wikipedia.org/wiki/Category:All_articles_containing_potentially_dated_statements {}\n",
      "https://en.wikipedia.org/wiki/Category:Use_dmy_dates_from_May_2020 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Pornhub&returntoquery=action%3Dinfo {}\n",
      "https://en.wikipedia.org/wiki/Category:CS1_German-language_sources_(de) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:Log&type=protect&page=Pornhub {}\n",
      "https://en.wikipedia.org/wiki/Category:All_Wikipedia_articles_written_in_Canadian_English {}\n",
      "https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_2020 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Pornhub&returntoquery=action%3Dinfo {}\n",
      "https://en.wikipedia.org/wiki/Category:Articles_with_short_description {}\n",
      "https://en.wikipedia.org/wiki/Category:Official_website_not_in_Wikidata {}\n",
      "https://en.wikipedia.org/wiki/Category:Short_description_is_different_from_Wikidata {}\n",
      "https://en.wikipedia.org/wiki/Category:Commons_category_link_from_Wikidata {}\n",
      "https://en.wikipedia.org/w/index.php?title=Pornhub&oldid=354928041 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Pornhub&hidelinks=1&hidetrans=1 {}\n",
      "https://en.wikipedia.org/wiki/YouPorn {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Aylo {}\n",
      "https://en.wikipedia.org/w/index.php?title=Aylo&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Aylo&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Aylo&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/Brazzers {}\n",
      "https://en.wikipedia.org/wiki/Digital_Playground {}\n",
      "https://en.wikipedia.org/wiki/Information_technology {}\n",
      "https://en.wikipedia.org/w/index.php?title=Aylo&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Mofos {}\n",
      "https://en.wikipedia.org/wiki/Men.com {}\n",
      "https://en.wikipedia.org/wiki/RedTube {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Aylo&id=1282826972&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Fabian_Thylmann {}\n",
      "https://en.wikipedia.org/wiki/File:Aylo_logo.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FAylo {}\n",
      "https://en.wikipedia.org/w/index.php?title=Aylo&oldid=1282826972 {}\n",
      "https://en.wikipedia.org/wiki/Xtube {}\n",
      "https://en.wikipedia.org/wiki/Talk:Aylo {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Aylo&action=show-download-screen {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Aylo {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FAylo {}\n",
      "https://en.wikipedia.org/wiki/Nutaku {}\n",
      "https://en.wikipedia.org/wiki/Talk:Amateur_pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FAmateur_pornography {}\n",
      "https://en.wikipedia.org/wiki/Sex_tape_(disambiguation) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FAmateur_pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Amateur_pornography&id=1260369928&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/America_Online {}\n",
      "https://en.wikipedia.org/wiki/MySpace {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&oldid=1260369928 {}\n",
      "https://en.wikipedia.org/wiki/Google_Groups {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Amateur+pornography {}\n",
      "https://en.wikipedia.org/wiki/Instant_camera {}\n",
      "https://en.wikipedia.org/wiki/Sexting {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/wiki/Yahoo_Groups {}\n",
      "https://en.wikipedia.org/wiki/Digital_cameras {}\n",
      "https://en.wikipedia.org/wiki/Flickr {}\n",
      "https://en.wikipedia.org/wiki/Camera_phone {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Amateur_pornography&action=show-download-screen {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=edit&section=3 {}\n",
      "https://en.wikipedia.org/wiki/Image_scanner {}\n",
      "https://en.wikipedia.org/wiki/Reality_pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Amateur+pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Amateur_pornography&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHolding_company {}\n",
      "https://en.wikipedia.org/wiki/Cayman_Islands_company_law {}\n",
      "https://en.wikipedia.org/wiki/Australian_corporate_law {}\n",
      "https://en.wikipedia.org/w/index.php?title=Holding_company&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Holding_company&action=edit {}\n",
      "https://en.wikipedia.org/wiki/United_Kingdom_company_law {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Holding+company {}\n",
      "https://en.wikipedia.org/wiki/Corporate_spin-off {}\n",
      "https://en.wikipedia.org/wiki/File:Society.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Holding_company&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Corporate_law_in_Vietnam {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHolding_company {}\n",
      "https://en.wikipedia.org/w/index.php?title=Holding_company&action=history {}\n",
      "https://en.wikipedia.org/wiki/Indian_company_law {}\n",
      "https://en.wikipedia.org/w/index.php?title=Holding_company&oldid=1282789153 {}\n",
      "https://en.wikipedia.org/wiki/Talk:Holding_company {}\n",
      "https://en.wikipedia.org/w/index.php?title=Holding_company&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Holding+company {}\n",
      "https://en.wikipedia.org/wiki/South_African_company_law {}\n",
      "https://en.wikipedia.org/wiki/British_Virgin_Islands_company_law {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Holding_company&id=1282789153&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/United_States_corporate_law {}\n",
      "https://en.wikipedia.org/wiki/Big_Brother_and_the_Holding_Company {}\n",
      "https://en.wikipedia.org/wiki/Anguillan_company_law {}\n",
      "https://en.wikipedia.org/wiki/French_company_law {}\n",
      "https://en.wikipedia.org/wiki/Corporate_law {}\n",
      "https://en.wikipedia.org/wiki/Category:Corporate_law {}\n",
      "https://en.wikipedia.org/wiki/Canadian_corporate_law {}\n",
      "https://en.wikipedia.org/wiki/European_corporate_law {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FInternet_pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Internet_pornography&oldid=1274452811 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Internet_pornography&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/FTP {}\n",
      "https://en.wikipedia.org/wiki/Terabytes {}\n",
      "https://en.wikipedia.org/wiki/Danni_Ashe {}\n",
      "https://en.wikipedia.org/w/index.php?title=Internet_pornography&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Internet+pornography {}\n",
      "https://en.wikipedia.org/wiki/Usenet_newsgroup {}\n",
      "https://en.wikipedia.org/w/index.php?title=Internet_pornography&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Internet_pornography&action=history {}\n",
      "https://en.wikipedia.org/wiki/XNXX {}\n",
      "https://en.wikipedia.org/wiki/Website {}\n",
      "https://en.wikipedia.org/w/index.php?title=Internet_pornography&action=info {}\n",
      "https://en.wikipedia.org/wiki/Talk:Internet_pornography {}\n",
      "https://en.wikipedia.org/wiki/XVideos {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FInternet_pornography {}\n",
      "https://en.wikipedia.org/wiki/List_of_pornographic_film_studios {}\n",
      "https://en.wikipedia.org/wiki/World_Wide_Web {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Internet+pornography {}\n",
      "https://en.wikipedia.org/wiki/XHamster {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Internet_pornography&id=1274452811&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Peer-to-peer_file_sharing {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Organizational_founder&id=1269356930&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/wiki/Philanthropist {}\n",
      "https://en.wikipedia.org/wiki/Regulation_D_(SEC) {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&action=info {}\n",
      "https://en.wikipedia.org/wiki/Organization {}\n",
      "https://en.wikipedia.org/wiki/Henry_Dunant {}\n",
      "https://en.wikipedia.org/wiki/Governing {}\n",
      "https://en.wikipedia.org/wiki/Entrepreneur {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Organizational_founder&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Entertainer {}\n",
      "https://en.wikipedia.org/wiki/Business {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Organizational+founder {}\n",
      "https://en.wikipedia.org/wiki/International_Red_Cross_and_Red_Crescent_Movement {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&action=history {}\n",
      "https://en.wikipedia.org/wiki/School {}\n",
      "https://en.wikipedia.org/wiki/Charitable_organization {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Organizational+founder {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOrganizational_founder {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&oldid=1269356930 {}\n",
      "https://en.wikipedia.org/wiki/File:Henry_Dunant-young.jpg {}\n",
      "https://en.wikipedia.org/wiki/U.S._Securities_and_Exchange_Commission {}\n",
      "https://en.wikipedia.org/wiki/Talk:Organizational_founder {}\n",
      "https://en.wikipedia.org/w/index.php?title=Organizational_founder&action=edit {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOrganizational_founder {}\n",
      "https://en.wikipedia.org/wiki/Startup_company {}\n",
      "https://en.wikipedia.org/wiki/Securities_regulation_in_the_United_States {}\n",
      "https://en.wikipedia.org/wiki/Montreal_(disambiguation) {}\n",
      "https://en.wikipedia.org/wiki/Old_Port_of_Montreal {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMontreal {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Montreal&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Talk:Montreal {}\n",
      "https://en.wikipedia.org/wiki/List_of_cities_in_Quebec {}\n",
      "https://en.wikipedia.org/w/index.php?title=Montreal&printable=yes {}\n",
      "https://en.wikipedia.org/wiki/File:Mtl_from_mont_royal_(cropped).jpg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Montreal {}\n",
      "https://en.wikipedia.org/w/index.php?title=Montreal&action=edit {}\n",
      "https://en.wikipedia.org/wiki/Notre-Dame_Basilica_(Montreal) {}\n",
      "https://en.wikipedia.org/wiki/Old_Montreal {}\n",
      "https://en.wikipedia.org/w/index.php?title=Montreal&oldid=1281860056 {}\n",
      "https://en.wikipedia.org/wiki/Montrealer_(disambiguation) {}\n",
      "https://en.wikipedia.org/wiki/File:Oratoire_Saint-Joseph_du_Mont-Royal_-_Montreal.jpg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMontreal {}\n",
      "https://en.wikipedia.org/wiki/File:Montreal_NDame1_tango7174.jpg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Montreal&id=1281860056&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Montreal {}\n",
      "https://en.wikipedia.org/wiki/File:Old_Montreal_2017.jpg {}\n",
      "https://en.wikipedia.org/wiki/Mariupol {}\n",
      "https://en.wikipedia.org/w/index.php?title=Montreal&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Montreal&action=history {}\n",
      "https://en.wikipedia.org/wiki/File:Montreal.ogg {}\n",
      "https://en.wikipedia.org/wiki/Downtown_Montreal {}\n",
      "https://en.wikipedia.org/wiki/Saint_Joseph%27s_Oratory {}\n",
      "https://en.wikipedia.org/wiki/File:Montreal_downtown_-_panoramio.jpg {}\n",
      "https://en.wikipedia.org/wiki/Service_quality {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit&section=3 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=info {}\n",
      "https://en.wikipedia.org/wiki/Terminology {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit {}\n",
      "https://en.wikipedia.org/wiki/File:Lima_waiter_PUCPeru_2010.jpg {}\n",
      "https://en.wikipedia.org/wiki/Season {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Service+%28economics%29 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Service+%28economics%29 {}\n",
      "https://en.wikipedia.org/wiki/Consumer {}\n",
      "https://en.wikipedia.org/wiki/Payment {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=history {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&oldid=1282419228 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit&section=2 {}\n",
      "https://en.wikipedia.org/wiki/Resource {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&printable=yes {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit&section=5 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Service_%28economics%29&id=1282419228&wpFormIdentifier=titleform {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit&section=1 {}\n",
      "https://en.wikipedia.org/wiki/Talk:Service_(economics) {}\n",
      "https://en.wikipedia.org/wiki/Public_utility {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Service_%28economics%29&action=show-download-screen {}\n",
      "https://en.wikipedia.org/wiki/Government {}\n",
      "https://en.wikipedia.org/wiki/Heterogeneity_in_economics {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FService_%28economics%29 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Service_(economics)&action=edit&section=4 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FService_%28economics%29 {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3ADownloadAsPdf%26action%3Dshow-download-screen%26page%3DPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3ADownloadAsPdf%26action%3Dshow-download-screen%26page%3DPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Special%3ADownloadAsPdf&returntoquery=action%3Dshow-download-screen%26page%3DPornhub {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Special%3ADownloadAsPdf&returntoquery=action%3Dshow-download-screen%26page%3DPornhub {}\n",
      "https://en.wikipedia.org/wiki/User:Offnfopt {}\n",
      "https://en.wikipedia.org/w/index.php?title=File:Pornhub-logo.svg&action=info {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFile%3APornhub-logo.svg {}\n",
      "https://en.wikipedia.org/wiki/Template:User_Pornhub {}\n",
      "https://en.wikipedia.org/wiki/User:Rtucker913/userboxes {}\n",
      "https://en.wikipedia.org/wiki/User:Sakdichot {}\n",
      "https://en.wikipedia.org/wiki/User:Cherylqueen_22 {}\n",
      "https://en.wikipedia.org/wiki/User:Azdrew {}\n",
      "https://en.wikipedia.org/wiki/User:Waffpng {}\n",
      "https://en.wikipedia.org/wiki/en:trademark {}\n",
      "https://en.wikipedia.org/wiki/User:Andrew_Pertsev {}\n",
      "https://en.wikipedia.org/wiki/User:Soundwave7711 {}\n",
      "https://en.wikipedia.org/wiki/User:Doge_MLG {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFile%3APornhub-logo.svg {}\n",
      "https://en.wikipedia.org/wiki/User:Whoop_whoop_pull_up {}\n",
      "https://en.wikipedia.org/wiki/User:SquidHomme {}\n",
      "https://en.wikipedia.org/w/index.php?title=File_talk:Pornhub-logo.svg&action=edit&redlink=1 {}\n",
      "https://en.wikipedia.org/wiki/User:IagoQnsi {}\n",
      "https://en.wikipedia.org/wiki/User:Raiyaka/Effects_of_pornography {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=File%3APornhub-logo.svg {}\n",
      "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=File%3APornhub-logo.svg {}\n",
      "https://en.wikipedia.org/wiki/public_domain {}\n",
      "https://en.wikipedia.org/enwiki/wiki/Special:PasswordReset {}\n",
      "https://en.wikipedia.org/enwiki/w/index.php?title=Special:CreateAccount&returnto=Main_Page&centralauthLoginToken=9d4b929f3e80865002381bf89a98aba7&usesul3=1&useformat=desktop {}\n",
      "https://en.wikipedia.org/enwiki/w/index.php?title=Special:UserLogin&returnto=Main_Page&centralauthLoginToken=9d4b929f3e80865002381bf89a98aba7&usesul3=1&useformat=desktop {}\n",
      "https://en.wikipedia.org/enwiki/w/index.php?title=Special:CreateAccount&returnto=Main_Page&centralauthLoginToken=9d4b929f3e80865002381bf89a98aba7&usesul3=1&useformat=desktop&campaign=loginCTA {}\n",
      "https://en.wikipedia.org/enwiki/w/index.php?title=Special:CreateAccount&returnto=Main_Page&centralauthLoginToken=a0f86d5915f4bfe5f76b954b8c573de1&usesul3=1&useformat=desktop {}\n",
      "https://en.wikipedia.org/enwiki/w/index.php?title=Special:UserLogin&returnto=Main_Page&centralauthLoginToken=a0f86d5915f4bfe5f76b954b8c573de1&usesul3=1&useformat=desktop {}\n",
      "Total nodes: 580\n",
      "Contains 'https://en.wikipedia.org/wiki/Data_science': False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 02:09:26,460 - INFO - Сохранение графа в HTML-файл\n",
      "2025-03-29 02:09:26,552 - INFO - Graph saved as c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\Pornhub.html and opened in browser\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivant\\Desktop\\proj\\WebsiteGraph\\graphs\\Pornhub.html | max_depth: 1 | max_links: 30 | crawl time: 4.401360988616943 | workers: 10\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting program\")\n",
    "graph1 = WebsiteGraphMP(\n",
    "    start_url=\"https://en.wikipedia.org/wiki/Pornhub\",\n",
    "    max_depth=1,\n",
    "    max_links=30,\n",
    "    #path_regex=r\"^/wiki/[A-Za-z_]+$\",\n",
    "    workers=10,\n",
    "    layout={\"physics\": True},\n",
    "    show_menu = True\n",
    ")()\n",
    "# Call instance to crawl\n",
    "\n",
    "print(graph1)  # Uses __str__\n",
    "print(repr(graph1))  # Uses __repr__\n",
    "# Iterate over nodes\n",
    "for node, data in graph1:\n",
    "    print(node, data)\n",
    "# Check length\n",
    "print(\"Total nodes:\", len(graph1))\n",
    "# Check membership\n",
    "print(\"Contains 'https://en.wikipedia.org/wiki/Data_science':\", \"https://en.wikipedia.org/wiki/Data_science\" in graph1)\n",
    "\n",
    "graph1.visualize(force_file_name='Pornhub')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
